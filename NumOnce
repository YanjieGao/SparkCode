import org.apache.spark.SparkContext
import org.apache.spark.SparkContext._

/**
 * Created by Administrator on 2014/8/16.
 * 海量数据，大部分数据出现两次，其中1个数出现一次，找到这个数。可以推广到k次
 */
object NumOnce {
  def computeOneNum(args: Array[String]) {
    val spark = new SparkContext("local[1]", "NumOnce",
      System.getenv("SPARK_HOME"), SparkContext.jarOfClass(this.getClass))
    val data1 = spark.parallelize(1 to 1000)
    val data2 = spark.parallelize(1 to 999)
    val data = spark.union(data1, data2)
    //每个分区分别对数据做异或运算，最后在reduceByKey阶段，将各分区异或运算的结果再
    //做异或运算合并。偶数次出现的数字，异或运算之后为0，奇数次出现的数字异或后为
    // 数字本身
    val result = data.mapPartitions(iter => {
        var temp = iter.next()
        while(iter.hasNext) {
          temp = temp^iter.next()
        }
        Seq((1, temp)).iterator
      }).reduceByKey(_^_).collect()
    println("num appear once is :"+result(0))
  }
}
